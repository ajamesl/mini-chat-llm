# SFT Training Config
SFT_MODEL_NAME: str = "Qwen/Qwen3-0.6B-Base"
SFT_OUTPUT_DIR: str = "./checkpoints/sft_model/"
SFT_TRAIN_BATCH_SIZE: int = 4
SFT_GRADIENT_ACCUMULATION_STEPS: int = 4
SFT_LEARNING_RATE: float = 1e-5
SFT_EVAL_BATCH_SIZE: int = 1
SFT_EVAL_STEPS: int = 2
SFT_MAX_INPUT_LENGTH: int = 1024
SFT_SAVE_STEPS: int = 1000
SFT_NUM_TRAIN_EPOCHS: int = 1
SFT_SEED: int = 42

# PPO Training Config
PPO_SFT_MODEL_PATH: str = "./checkpoints/sft_model"
PPO_REWARD_MODEL_PATH: str = "Skywork/Skywork-Reward-V2-Qwen3-0.6B"
PPO_BASE_MODEL: str = "Qwen/Qwen3-0.6B-Base"
PPO_OUTPUT_DIR: str = "./checkpoints/ppo_model"
PPO_DATASET_NAME: str = "OpenAssistant/oasst1"
PPO_DATASET_SPLIT: str = "train"
PPO_PROMPT_COLUMN: str = "text"
PPO_EVAL_SAMPLES: int = 100
PPO_PER_DEVICE_TRAIN_BATCH_SIZE: int = 1
PPO_GRADIENT_ACCUMULATION_STEPS: int = 1
PPO_LEARNING_RATE: float = 3e-6
PPO_NUM_PPO_EPOCHS: int = 1
PPO_TOTAL_EPISODES: int = 1500
